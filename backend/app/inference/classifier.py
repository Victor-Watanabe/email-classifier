# backend/app/inference/classifier.py

import joblib
import os
from typing import Dict

from app.nlp.preprocess import preprocess_text
from app.nlp.vectorizer import transform_text, set_vectorizer
from app.inference.gemini_service import query_gemini

# ============================
# Paths dos modelos
# ============================
MODEL_PATH = "app/models/classifier.joblib"
VECTORIZER_PATH = "app/models/vectorizer.joblib"

# ============================
# Configura√ß√µes
# ============================
CONFIDENCE_THRESHOLD = 0.75
MIN_TOKEN_LENGTH = 3  # evita textos vazios ou irrelevantes

# ============================
# Respostas fixas (SEM Gemini)
# ============================
FIXED_REPLIES = {
    "PRODUTIVO": (
        "Ol√°! Recebemos sua mensagem e ela foi encaminhada para an√°lise. "
        "Nossa equipe retornar√° com mais informa√ß√µes o mais breve poss√≠vel."
    ),
    "IMPRODUTIVO": (
        "Ol√°! Agradecemos o contato. Sua mensagem foi recebida com sucesso."
    )
}

# ============================
# Load models
# ============================
if not os.path.exists(MODEL_PATH) or not os.path.exists(VECTORIZER_PATH):
    raise FileNotFoundError(
        "Modelos ou vectorizer n√£o encontrados. Treine antes de iniciar."
    )

trained_vectorizer = joblib.load(VECTORIZER_PATH)
set_vectorizer(trained_vectorizer)

classifier_model = joblib.load(MODEL_PATH)

# ============================
# Confidence calibration
# ============================
def boost_confidence(confidence: float) -> float:
    """
    Reduz o excesso de cautela da Logistic Regression
    sem alterar a classe prevista.
    """
    if confidence >= 0.5:
        return min(1.0, confidence ** 0.5)
    return confidence

# ============================
# Classifica√ß√£o principal
# ============================
def classify_email(text: str) -> Dict:
    """
    Classifica um email como PRODUTIVO ou IMPRODUTIVO.

    Fluxo:
    - Regra de neg√≥cio para textos vazios/curtos
    - Classifica√ß√£o local (TF-IDF + Logistic Regression)
    - Fallback para Gemini em caso de baixa confian√ßa
    """

    print("üîπ Texto original:", text)

    # 1Ô∏è‚É£ Pr√©-processamento
    clean_text = preprocess_text(text)
    print("üîπ Texto pr√©-processado:", clean_text)

    # üö® REGRA DE NEG√ìCIO: texto vazio ou irrelevante
    if not clean_text or len(clean_text.split()) < MIN_TOKEN_LENGTH:
        result = {
            "text": text,
            "prediction": "IMPRODUTIVO",
            "confidence": 0.95,
            "reply": FIXED_REPLIES["IMPRODUTIVO"],
            "source": "rule_based",
            "note": "Texto vazio, curto ou sem conte√∫do acion√°vel."
        }
        print("üîπ Resultado final (regra de neg√≥cio):", result)
        return result

    # 2Ô∏è‚É£ Vetoriza√ß√£o
    vector = transform_text(clean_text).toarray()

    # 3Ô∏è‚É£ Classifica√ß√£o local
    prediction = classifier_model.predict(vector)[0]
    probabilities = classifier_model.predict_proba(vector)[0]
    class_index = list(classifier_model.classes_).index(prediction)
    raw_confidence = probabilities[class_index]
    confidence = boost_confidence(raw_confidence)

    print(
        f"üîπ Predi√ß√£o local: {prediction}, "
        f"Confian√ßa bruta: {raw_confidence:.3f}, "
        f"Confian√ßa ajustada: {confidence:.3f}"
    )

    # 4Ô∏è‚É£ Confian√ßa suficiente ‚Üí usa IA LOCAL
    if confidence >= CONFIDENCE_THRESHOLD:
        result = {
            "text": text,
            "prediction": prediction,
            "confidence": round(float(confidence), 3),
            "reply": FIXED_REPLIES[prediction],
            "source": "local_model"
        }
        print("üîπ Resultado final (modelo local):", result)
        return result

    # 5Ô∏è‚É£ Confian√ßa baixa ‚Üí fallback Gemini
    print("‚ö†Ô∏è Confian√ßa abaixo do threshold. Consultando Gemini...")

    gemini_response = query_gemini(text)

    result = {
        "text": text,
        "prediction": gemini_response.get("classification"),
        "reply": gemini_response.get("suggested_reply"),
        "justification": gemini_response.get("justification"),
        "confidence": round(float(confidence), 3),
        "source": "gemini_fallback"
    }

    print("üîπ Resultado final (Gemini):", result)
    return result
