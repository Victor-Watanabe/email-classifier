# backend/app/inference/classifier.py

import joblib
import os
#import csv

from typing import Dict
from app.pipeline.preprocess import preprocess_text
from app.pipeline.vectorizer import transform_text, set_vectorizer
from ..inference.gemini_service import query_gemini

# Paths dos modelos
MODEL_PATH = "app/models/classifier.joblib"
VECTORIZER_PATH = "app/models/vectorizer.joblib"

# Dataset incremental (Gemini)
# DATASET_DIR = "app/training/datasets"
# DATASET_PATH = f"{DATASET_DIR}/gemini_feedback.csv"

# Configura√ß√µes
CONFIDENCE_THRESHOLD = 0.75
MIN_TOKEN_LENGTH = 3

# ============================
# Respostas fixas (SEM Gemini)
# ============================
FIXED_REPLIES = {
    "PRODUTIVO": (
        "Ol√°! Recebemos sua mensagem e ela foi encaminhada para an√°lise. "
        "Nossa equipe retornar√° com mais informa√ß√µes o mais breve poss√≠vel."
    ),
    "IMPRODUTIVO": (
        "Ol√°! Agradecemos o contato. Sua mensagem foi recebida com sucesso."
    )
}

# Load models
if not os.path.exists(MODEL_PATH) or not os.path.exists(VECTORIZER_PATH):
    raise FileNotFoundError(
        "Modelos ou vectorizer n√£o encontrados. Treine antes de iniciar."
    )

trained_vectorizer = joblib.load(VECTORIZER_PATH)
set_vectorizer(trained_vectorizer)

classifier_model = joblib.load(MODEL_PATH)

# Confidence calibration
def boost_confidence(confidence: float) -> float:
    if confidence >= 0.5:
        return min(1.0, confidence ** 0.5)
    return confidence

# üîÆ FUN√á√ÉO FUTURA (COMENTADA)
# 
# def save_gemini_feedback(email_text: str, classification: str):
#     """
#     FUTURO:
#     Salva classifica√ß√µes realizadas pelo Gemini em um CSV
#     para aprendizado supervisionado incremental.
#
#     ‚ö†Ô∏è Este recurso est√° DESABILITADO no momento.
#     A proposta √© permitir que um humano revise os dados
#     antes de re-treinar o modelo local.
#     """
#
#     os.makedirs(DATASET_DIR, exist_ok=True)
#     file_exists = os.path.exists(DATASET_PATH)
#
#     with open(DATASET_PATH, mode="a", newline="", encoding="utf-8") as file:
#         writer = csv.writer(file)
#
#         if not file_exists:
#             writer.writerow(["email_text", "classification"])
#
#         writer.writerow([email_text, classification])

# Classifica√ß√£o principal
def classify_email(text: str) -> Dict:
    print("üîπ Texto original:", text)

    # 1Ô∏è‚É£ Pr√©-processamento
    clean_text = preprocess_text(text)
    print("üîπ Texto pr√©-processado:", clean_text)

    # üö® REGRA DE NEG√ìCIO
    if not clean_text or len(clean_text.split()) < MIN_TOKEN_LENGTH:
        result = {
            "text": text,
            "prediction": "IMPRODUTIVO",
            "confidence": 0.95,
            "reply": FIXED_REPLIES["IMPRODUTIVO"],
            "source": "rule_based",
            "note": "Texto vazio, curto ou sem conte√∫do acion√°vel."
        }
        return result

    # 2Ô∏è‚É£ Vetoriza√ß√£o
    vector = transform_text(clean_text).toarray()

    # 3Ô∏è‚É£ Classifica√ß√£o local
    prediction = classifier_model.predict(vector)[0]
    probabilities = classifier_model.predict_proba(vector)[0]
    class_index = list(classifier_model.classes_).index(prediction)
    raw_confidence = probabilities[class_index]
    confidence = boost_confidence(raw_confidence)

    print(
        f"üîπ Predi√ß√£o local: {prediction}, "
        f"Confian√ßa ajustada: {confidence:.3f}"
    )

    # 4Ô∏è‚É£ Confian√ßa suficiente ‚Üí modelo local
    if confidence >= CONFIDENCE_THRESHOLD:
        return {
            "text": text,
            "prediction": prediction,
            "confidence": round(float(confidence), 3),
            "reply": FIXED_REPLIES[prediction],
            "source": "local_model"
        }

    # 5Ô∏è‚É£ Confian√ßa baixa ‚Üí Gemini
    print("‚ö†Ô∏è Confian√ßa baixa. Consultando Gemini...")

    gemini_response = query_gemini(text)
    gemini_classification = gemini_response.get("classification")

    # üß† Salva para aprendizado futuro
    #if gemini_classification:
    #   save_gemini_feedback(text, gemini_classification)

    return {
        "text": text,
        "prediction": gemini_classification,
        "reply": gemini_response.get("suggested_reply"),
        "justification": gemini_response.get("justification"),
        "confidence": round(float(confidence), 3),
        "source": "gemini_fallback"
    }